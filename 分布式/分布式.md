# 集群

集群调度架构 

[(3条消息) 十大主流集群调度系统大盘点_不正常IT研究所的博客-CSDN博客](https://blog.csdn.net/vip_iter/article/details/80123228)



# 分布式

​	微服务: 项目的一种架构方式(概念),如mvc架构

​	sc 则是这种架构的一种技术实现

​	同时微服务则一定需要分布式解决方案



与集群的区别:

-  分布式是指将不同的业务分布在不同的地方

- 集群指的是将几台服务器集中在一起，实现同一业务
- 分布式的每一个节点，都可以做集群，而集群并不一定就是分布式的。 而分布式，从狭义上理解，也与集群差不多，但是它的组织比较松散，不像集群，有一定组织性，一台服务器宕了，其他的服务器可以顶上来。分布式的每一个节点，都完成不同的业务，一个节点宕了，这个业务就不可访问了

## 场景

用户- 分布式session

报表-分布式调度

秒杀-分布式限流

订单-分布式id,分库分表,分布式事务



#  分布式id

传统方案: 自增/时间戳 uuid

分布式id特点:

1. 全局唯一
   - 应用只部署在一个服务器上,生成id唯一
   - 应用只部署在一个服务器上,生成id唯一
   - 应用只部署在同一个服务器上不同的docker容器中,生成id唯一
2. 高并发
3. 高可用



方案优缺点:

1. UUID 

   缺点: 1.空间占用多 2.索引效率低

2. 数据库自增组件

   缺点: 1.并发性能不高,受限于数据库性能  2. 针对缺点1 分库分表 需要改造 较复杂  3.业务数据容易泄露

3. redis自增

   优点: 并发性能相对方案2高

   缺点: 1. 数据丢失(rdb至少丢失1s数据,aof可以做到不丢失但地洞回复速度慢) 2.业务数据容易泄露

4. 雪花算法(snowflake)

   优点: 不依赖外部组件(如数据库,redis等)

   缺点: 时钟回拨

5. 号段模式

   缺点: 仍然依赖数据库,且仍然是自增

   优点: 一次获取多个可用id,性能提高



自研算法分析:

时间戳(ms) 同一ms可能有多个请求

时间戳(ms)+随机数  减少重复的概率,但无法完全保证唯一

时间戳(ms)+自增数(AtomicInteger) 同一台机器(容器)保证唯一,但多台机器无法保证

时间戳(ms)+机器序号+自增数(AtomicInteger)



雪花算法就是类似上述

比如:

1bit 符号位(舍弃)

41bit  时间戳

10bit 工作进程位=5bit 区域 + 5bit 机器序号

12bit 序列号位

大小可以自定义







## generator(百度)

雪花算法

https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md









## Tinyid(滴滴)

https://github.com/didi/tinyid

https://github.com/didi/tinyid/wiki

基于数据库号段算法

多DB,高可用,java-client

##  Leaf(美团)

号段模式和snowflake模式

https://github.com/Meituan-Dianping/Leaf/blob/master/README_CN.md

用到zookeeper,程序运行在docker等(手动配置不方便),自动上报服务器标识到zk,zk存储

分布式id以此为例(spring boot)

1. 引入依赖

   ```<dependency>
   <dependency>
   	<artifactId>leaf-boot-starter</artifactId>
       <groupId>com.sankuai.inf.leaf</groupId>
       <version>1.0.1-RELEASE</version>
   </dependency>
   ```

   1.1 若maven仓库没有 需要先下载install

   ```
   git clone git@github.com:Meituan-Dianping/Leaf.git
   或 
   git clone https://github.com/Meituan-Dianping/Leaf.git
   cd leaf
   git checkout feature/spring-boot-starter
   mvn clean install -Dmaven.test.skip=true 
   ```

2. 配置leaf.properties

   ```
   leaf.name=com.sankuai.leaf.opensource.test
   leaf.segment.enable=false
   #leaf.segment.url=
   #leaf.segment.username=
   #leaf.segment.password=
   
   leaf.snowflake.enable=false
   #leaf.snowflake.address=
   #leaf.snowflake.port=
   ```

3. @EnableLeafServer

4.     @Autowired
       private SegmentService segmentService;
       @Autowired
       private SnowflakeService snowflakeService;

5. 表结构(号段模式)

   ```
   CREATE DATABASE leaf;
   use leaf;
   CREATE TABLE `leaf_alloc` (
     `biz_tag` varchar(128)  NOT NULL DEFAULT '',
     `max_id` bigint(20) NOT NULL DEFAULT '1',
     `step` int(11) NOT NULL,
     `description` varchar(256)  DEFAULT NULL,
     `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
     PRIMARY KEY (`biz_tag`)
   ) ENGINE=InnoDB;
   
   insert into leaf_alloc(biz_tag, max_id, step, description) values('leaf-segment-test', 1, 2000, 'Test leaf Segment Mode Get Id')
   ```

   

6. ```
   @RequestMapping("/leaf")
   public class LeafController {
       @Autowired
       private SegmentService segmentService;
   /*    @Autowired
       private SnowflakeService snowflakeService;*/
   
       @GetMapping("/segment")
       public long segment(){
          return segmentService.getId("leaf-segment-test").getId(); //对应leaf-alloc biz_tag字段
       }
   }
   ```



雪花模式需要先搭建zk服务器



问题:

1. java.sql.SQLException: validateConnection false

   版本问题

   比如druid 1.0.18 需要匹配5.1.38的mysql-connector-java

   3.3.1的mybatis

   这里升级druid

   ```
   <dependency>
      <groupId>com.alibaba</groupId>
      <artifactId>druid</artifactId>
      <version>1.2.5</version>
   </dependency>
   <dependency>
   			<groupId>org.mybatis</groupId>
   			<artifactId>mybatis</artifactId>
   			<version>3.4.0</version>
   		</dependency>
   ```

   



# 分布式session

## 分类

### 传统session



![image-20220803135327995](assets/image-20220803135327995.png)



问题一: session存在哪里

​	一般情况下,session都是存储在内存中(服务器(tomcat)中),可以设置session持久化,在服务器重启时能够加载

问题二: nginx做了负载均衡,可能导致登录失效问题,怎么解决?

 1. 做某种规则,让特定用户访问特定服务器,如张三始终访问服务器1

    问题: 破坏了高可用,服务器1挂了,nginx的请求仍会转发到服务器1.

 2. 既然是session存在不同地方导致的,那就把session存在同一地方,如redis



session 原理:



![image-20220803142925996](assets/image-20220803142925996.png)

**浏览器第一次访问服务器的时候,服务器会生成一个sessionid,并返回给浏览器,这个sessionid会保存在浏览器的cookie会话中**

这个机制是根据浏览器中是不是有cookie,没有就重新生成(删除cookie记录后就没有了)

set-Cookie



问题:跨域

http://localhost:8080/ 

http://127.0.0.1:8080/

上述两个代表不同的域,当分别访问时会生成不同的cookie



总结:

1. 访问同一服务器下不同的web容器(如tomcat,可以是同一应用)生成不同的sessionId
2. 以不同域访问一个web容器(localhost,127.0.0.1 ),生成不同的sessionId

### spring-session

将session存到redis

1. redisTemplate
2. spring-session-data-redis

```
<dependency>
   <groupId>org.springframework.session</groupId>
   <artifactId>spring-session-data-redis</artifactId>
</dependency>
```

```
spring.session.store-type=redis
spring.session.timeout=3600
spring.session.redis.namespace=login:user //spring:Session扔存在,生成两份
```

如果redis集群配置的, spring.redis下配置



Spring Session makes it trivial(微不足道) to support clustered sessions without being tied to(be bounded to) an application container specific solution. It also provides transparent (透明)integration with

1. `HttpSession` - allows replacing the HttpSession in an application container (i.e. Tomcat) neutral(中立,非侵入式) way, with support for providing session IDs in headers to work with RESTful APIs

   原来Httpsession怎么用,现在就怎么用  `HttpSessionWrapper`

2. `WebSocket` - provides the ability to keep the HttpSession alive when receiving WebSocket messages

3. `WebSession` - allows replacing the Spring WebFlux’s WebSession in an application container neutral way



源码分析:

1. SessionRepositoryFilter.SessionRepositoryRequestWrapper implements HttpServletRequestWrapper

2. SessionRepositoryFilter.SessionRepositoryRequestWrapper implements HttpServletRequestWrapper
   SessionRepositoryFilter<S extends Session> extends OncePerRequestFilter

3. parent.doFilter -> child.doFilterInternal -> ApplicationFilterChain.doFilter ->Call the next filter if there is one(pos<n)

4. FilterChains

   ```
   0 = {ApplicationFilterConfig@10174} "ApplicationFilterConfig[name=characterEncodingFilter, filterClass=org.springframework.boot.web.servlet.filter.OrderedCharacterEncodingFilter]"
   1 = {ApplicationFilterConfig@10175} "ApplicationFilterConfig[name=sessionRepositoryFilter, filterClass=org.springframework.session.web.http.SessionRepositoryFilter]"
   2 = {ApplicationFilterConfig@10108} "ApplicationFilterConfig[name=formContentFilter, filterClass=org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]"
   3 = {ApplicationFilterConfig@10176} "ApplicationFilterConfig[name=requestContextFilter, filterClass=org.springframework.boot.web.servlet.filter.OrderedRequestContextFilter]"
   4 = {ApplicationFilterConfig@10177} "ApplicationFilterConfig[name=Tomcat WebSocket (JSR356) Filter, filterClass=org.apache.tomcat.websocket.server.WsFilter]"
   ```

   

快捷键: ctrl+alt+左键 弹出实现(类和方法)

#### servlet和interceptor的区别

这两者在功能方面很类似,并且都是通过AOP(一种思想,横向切面,对OOP纵向扩展的补充)的具体技术实现.但在具体技术实现方面，差距还是比较大的.

区别:

- Filter是依赖于Servlet[容器](https://cloud.tencent.com/product/tke?from=10680)，属于Servlet规范的一部分，而拦截器则是独立存在的，可以在任何情况下使用。

- Filter的执行由Servlet容器回调完成，而拦截器通常通过动态代理的方式来执行。

  默认有上述5个

  ```
  @WebFilter(urlPatterns = "/*",filterName="filter3")
  public class MyFilter1 implements Filter {
  
      @Override
      public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
      	...
          chain.doFilter(request,response);
          ...
    }
  ```

  ApplicationFilterChain.doFilter 链式  

  ```
  ...
  filter.doFilter(request, response, this);
  ...
  return;
  ```

  先进入doFilter方法 后结束

- Filter的生命周期由Servlet容器管理，而拦截器则可以通过IoC容器来管理，因此可以通过注入等方式来获取其他Bean的实例，因此使用会更方便。

```
@Configuration
public class WebConfigure extends WebMvcConfigurerAdapter {
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
//        registry.addInterceptor(new MyInterceptor1()).addPathPatterns("/**");
    }
}

public class MyInterceptor1 implements HandlerInterceptor {
```

注意: urlPatterns /*  pathPatterns /**





### token+redis

token+redis自由度高(移动端不太喜欢用cookie,以上两种都是基于cookie)

cookie的缺陷

1. 不安全
2. 大小有限,只能存储简单的字符串
3. 能够被禁用,删除



**token推荐存在header里**

@RequestHeader可以获得全部cookie

@CookieValue("SESSION") 从cookie中获取指定key的值

​	Cookie: 

​	JSESSIONID=40D2D611E06D4DB13DCD35F1B5220E0F; SESSION=ZGQzYTIyOTktODk0Yi00NDczLWJiNzktYjNkOWEyZDE5Nzc5;...









### jwt

JSON WEB TOKEN 一种协议

jwt.io



```
<dependency>
    <groupId>com.auth0</groupId>
    <artifactId>java-jwt</artifactId>
    <version>4.0.0</version>
</dependency>
```


#### 实例

Example using `HS256`

1. create

   ```
   Algorithm algorithm = Algorithm.HMAC256("token_secret");
   String token = JWT.create()
           .withClaim("login_user",username
           .withExpiresAt()  //TokenExpiredException
           .sign(algorithm);
   ```

2. verify

   ```
   Algorithm algorithm = Algorithm.HMAC256("token_secret");
   JWTVerifier verifier = JWT.require(algorithm)
           .build(); //Reusable verifier instance
   DecodedJWT jwt = verifier.verify(token); //JWTCreationException JWTDecodeException
   jwt.getClaim("login_user").asString()
   ```

3. DecodedJWT

   组成部分: header,payload,verify signature,token

   token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJsb2dpbl91c2VyIjoiYWRtaW4ifQ.Cq1TvoFJHvNjXhSecW1Kovx1Aymud3GXQEmThAH7evQ

   header=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9

   {
     "typ": "JWT",
     "alg": "HS256"
   }

   

   payload(data)=eyJsb2dpbl91c2VyIjoiYWRtaW4ifQ

   {
     "login_user": "admin"
   }

   

   signature=Cq1TvoFJHvNjXhSecW1Kovx1Aymud3GXQEmThAH7evQ

   ```
   HMACSHA256(
     base64UrlEncode(header) + "." +
     base64UrlEncode(payload),
     your-256-bit-secret
   )
   ```



当传递非之前生成的token 会报错(可解析,但防篡改)

```
com.auth0.jwt.exceptions.SignatureVerificationException: The Token's Signature resulted invalid when verified using the Algorithm: HmacSHA256
```

原因: 在生成jwt的时候Algorithm.HMAC256加入了自定义的`JWT_SECRET`,因此要妥善保存`JWT_SECRET`

#### claims

Claims are issued by(be provided by) a provider, and they are given one or more values and then packaged in security tokens that are issued by an issuer, commonly known as a security token(令牌) service (STS). Claim is **piece of information that describes given identity(身份) on some aspect**. Take claim as name-value pair

## 拦截器统一处理token

```
public class JwtInterceptor implements HandlerInterceptor {
    //如果该类注入了其他组件,如redisTemplate需要将该拦截器注册为组件,在WebConfigure注入
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        try {
            String token=request.getHeader("token");
            if(StringUtils.isBlank(token)){
                throw  new RuntimeException("token must be passed in header");
            }
            Algorithm algorithm = Algorithm.HMAC256("token_secret");
            JWTVerifier verifier = JWT.require(algorithm)
                    .build(); //Reusable

            // verifier instance
            DecodedJWT jwt = verifier.verify(token);
            //同一个request,session,redis都能存储
/*            request.getSession().setAttribute("login_user",
                    jwt.getClaim("login_user").asString());*/
            request.setAttribute("login_user",
                    jwt.getClaim("login_user").asString()); //@RequestAttribute
            return true;
        } catch (Exception exception){
            //Invalid signature/claims
            exception.printStackTrace();
        }
        return false;
    }
}
```

jwt.getClaim("login_user").asString() 注意数据类型 如果login_user是int类型,asString()->null



## Oauth2

授权机制,跟JWT完全不一样

比如qq授权慕课网(第三方)获取用户信息



spring-security-oauth2

1. 授权数据给第三方
2. 权限管理





# 分布式任务调度

场景

1. 报表

2. 日/月结单

3. 爬虫

4. 数据归档

   ...

总结: 基于时间+基于数据的任务调度



## 非分布式

@Scheduled

```
@Slf4j
@Component
@EnableScheduling
public class ScheduleJob {

    @SneakyThrows
    @Scheduled(fixedRate = 3000,initialDelay = 4000)
    public void shcedule(){
        log.info("job start....");
        Thread.sleep(2000);
        log.info("job end....");
    }
}
```

### 参数分析

- initialDelay: Number of units of time to delay before the first execution of a fixedRate or fixedDelay task.

- fixedRate:  a fixed period between invocations 上一次调用开始到这次调用开始中间的时间

- fixedDelay:a fixed period between the end of the last invocation and the start of the next 上一次调用结束到这次调用开始的间隔时间

* cron expressions

  https://cron.qqe2.com/

  1. Seconds
  2. Minutes
  3. Hours
  4. Day-of-Month
  5. Month
  6. Day-of-Week
  7. Year (optional field)

  上述自表达式用空格隔开

    “0 0 12？* WED“ - 这意味着”每个星期三下午12:00“

  分钟 0/15 0,15都表示从0开始每隔15分钟

  *每个可能的值（枚举）

  ？表示无特定值的日期和星期几 表达式中只有1个?

  L

  * 月 月末
  * 周 7或SAT
  * 6L 或 FRIL本月最后一个周五

  W 指定最近给定日期的工作日（星期一至星期五） 15W表示最近15日的工作日

  “6＃3”或“FRI＃3” 本月的第3个星期5

* ```
  MISFIRE_INSTRUCTION_FIRE_ONCE_NOW
  MISFIRE_INSTRUCTION_DO_NOTHING
  ```

### 多线程

```
@SneakyThrows
@Scheduled(fixedRate = 3000)
public void shcedule(){
    log.info("job1 start....");
    Thread.sleep(5000);
    log.info("job1 end....");
}

@SneakyThrows
@Scheduled(fixedRate = 3000)
public void shcedule2(){
    log.info("job2 start....");
    Thread.sleep(5000);
    log.info("job2 end....");
}
```

![image-20220808091605730](assets/image-20220808091605730.png)

通过日志可以了解到,只有main线程交替执行各个schedule

如果想并发执行schedule,各个schedule独立执行,可以引入多线程

```
@Bean
public TaskScheduler taskScheduler(){
    ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();
    taskScheduler.setPoolSize(5);
    return taskScheduler;
}
```

![image-20220808092219247](assets/image-20220808092219247.png)



fixedRate = 3000,如果task执行所需时间>3s,此时两个task开始之间间隔>3s,如果我想task只要到了3s就要重新起一个,可以考虑异步.

1. ```
   @Slf4j
   @Async
   @Component
   public class AsynTaskService {
   
       @SneakyThrows
       public void doAsynProcess(){
           log.info("doProcess1 start ");
           Thread.sleep(5000);
           log.info("doProcess1 end ");
       }
   }
   ```

2. ```
   @Autowired
   private AsynTaskService asynTaskService;
    @Scheduled(fixedRate = 3000)
       public void shcedule(){
           log.info("job1 start....");
           asynTaskService.doAsynProcess();
           log.info("job1 end....");
       }
   
   ```

3. ```
   @EnableAsync
   ```



![image-20220808100900320](assets/image-20220808100900320.png)

job1和doProcess1用不同的线程池管理.





当task急剧增多,单机难以处理,此时可以考虑分布式

## 分布式

1. Quartz

   借助数据库实现分布式

   参照quartz.md

2. Elasticjob

3. XXL-JOB

4. ScheduledX

5. PowerJob

   |                | QuartZ                           | xxl-job                                  | SchedulerX 2.0                                    | **PowerJob**                                                 |
   | -------------- | -------------------------------- | ---------------------------------------- | ------------------------------------------------- | ------------------------------------------------------------ |
   | 定时类型       | CRON                             | CRON                                     | CRON、固定频率、固定延迟、OpenAPI                 | **CRON、固定频率、固定延迟、OpenAPI**                        |
   | 任务类型       | 内置Java                         | 内置Java、GLUE Java、Shell、Python等脚本 | 内置Java、外置Java（FatJar）、Shell、Python等脚本 | **内置Java、外置Java（容器）、Shell、Python等脚本**          |
   | 分布式任务     | 有                               | 静态分片                                 | MapReduce 动态分片                                | **MapReduce 动态分片**                                       |
   | 在线任务治理   | 不支持                           | 支持                                     | 支持                                              | **支持**                                                     |
   | 日志白屏化     | 不支持                           | 支持                                     | 不支持                                            | **支持**                                                     |
   | 调度方式及性能 | 基于数据库锁，有性能瓶颈         | 基于数据库锁，有性能瓶颈                 | 不详                                              | **无锁化设计，性能强劲无上限**                               |
   | 报警监控       | 无                               | 邮件                                     | 短信                                              | **邮件，提供接口允许开发者扩展**                             |
   | 系统依赖       | 关系型数据库（MySQL、Oracle...） | MySQL                                    | 人民币                                            | **任意 Spring Data Jpa支持的关系型数据库（MySQL、Oracle...）** |
   | DAG 工作流     | 不支持                           | 不支持                                   | 支持                                              | **支持**                                                     |

   









## XXL-JOB

![1659958634670](assets/1659958634670.png)

### 配置部署调度中心

1. https://github.com/xuxueli/xxl-job

   http://gitee.com/xuxueli0323/xxl-job

   下载到本地

   mvn clean install -Dmaven.test.skip=true(可选)

   1. `xxl-job-admin：调度中心`
   2. `xxl-job-core：公共依赖`
   3. `xxl-job-executor-samples：执行器Sample示例（选择合适的版本执行器，可直接使用，也可以参考其并将现有项目改造成执行器）`
   4. `    ：xxl-job-executor-sample-springboot：Springboot版本，通过Springboot管理执行器，推荐这种方式；`
   5. `    ：xxl-job-executor-sample-frameless：无框架版本；`

2. 初始化数据库表

   `/xxl-job/doc/db/tables_xxl_job.sql`

3. 配置部署"调度中心"(也就是后台,可通过Docker 部署)

   1. 修改配置`/xxl-job/xxl-job-admin/src/main/resources/application.properties`

   ```
   ### 调度中心JDBC链接：链接地址请保持和 2.1章节 所创建的调度数据库的地址一致
   spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai
   spring.datasource.username=root
   spring.datasource.password=root_pwd
   spring.datasource.driver-class-name=com.mysql.jdbc.Driver
   ### 报警邮箱
   spring.mail.host=smtp.qq.com
   spring.mail.port=25
   spring.mail.username=xxx@qq.com
   spring.mail.password=xxx
   spring.mail.properties.mail.smtp.auth=true
   spring.mail.properties.mail.smtp.starttls.enable=true
   spring.mail.properties.mail.smtp.starttls.required=true
   spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory
   ### 调度中心通讯TOKEN [选填]：非空时启用；
   xxl.job.accessToken=
   ### 调度中心国际化配置 [必填]： 默认为 "zh_CN"/中文简体, 可选范围为 "zh_CN"/中文简体, "zh_TC"/中文繁体 and "en"/英文；
   xxl.job.i18n=zh_CN
   ## 调度线程池最大线程配置【必填】
   xxl.job.triggerpool.fast.max=200
   xxl.job.triggerpool.slow.max=100
   ### 调度中心日志表数据保存天数 [必填]：过期日志自动清理；限制大于等于7时生效，否则, 如-1，关闭自动清理功能；
   xxl.job.logretentiondays=30
   ```

   

   2. 将E:\xxl-job\xxl-job-admin打包部署在服务器上

      java -jar  xxl-job-admin-2.4.0-SNAPSHOT.jar

      http://localhost:8080/xxl-job-admin (该地址执行器将会使用到，作为回调地址)

      admin/123456

   3. 调度中心集群(可选)



通过Docker部署

2.3.0

1. docker pull xuxueli/xxl-job-admin:{指定版本} 

2. docker run -p 8090:8090 -v E:\docker_logs:/data/applogs --name xxl-job-admin  -d xuxueli/xxl-job-admin:2.3.0

   | `--detach` , `-d` |      | Run container in background and print container ID           |
   | ----------------- | ---- | ------------------------------------------------------------ |
   |                   |      | **将子线程和主线程的关联分离** ,子线程在后台独立继续运行，主线程无法再取得子线程的控制权，即使主线程结束，子线程未执行也不会结束。 |

   ```
   /**
   * 如需自定义 mysql 等配置，可通过 "-e PARAMS" 指定，参数格式 PARAMS="--key=value  --key2=value2" ；
   * 配置项参考文件：/xxl-job/xxl-job-admin/src/main/resources/application.properties
   * 如需自定义 JVM内存参数 等配置，可通过 "-e JAVA_OPTS" 指定，参数格式 JAVA_OPTS="-Xmx512m" ；
   */
   ```

   docker run -e PARAMS="--spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai" -p 8088:8088 -v E:\docker_logs:/data/applogs --name xxl-job-admin  -d xuxueli/xxl-job-admin:2.3.0 

  



问题：21:01:11.874 logback [xxl-job, admin JobFailMonitorHelper] ERROR com.zaxxer.hikari.pool.HikariPool - HikariCP - Exception during pool initialization. java.sql.SQLNonTransientConnectionException: Could not create connection to database server. Attempted reconnect 3 times. Giving up

原因: 没有在docker安装mysql且docker run参数不够全面（可以使用多容器通信 也可以使用--link）

解决：

1. docker pull mysql:8.0.30

2. docker network create xxl-job

3. docker run -d --network xxl-job -p 3307:3306 --name mysql8  -v E:\docker_logs\mysql:/var/log/mysql  -v E:\docker\mysql\data:/var/lib/mysql  -v E:\docker\mysql\conf:/etc/mysql/conf.d  -e MYSQL_ROOT_PASSWORD=root  mysql:8.0.30

   可能的问题：mysqld: Can't read dir of '/etc/mysql/conf.d/' (OS errno 2 - No such file or directory) 

   解决：

   1. 先去掉 -v E:\docker\mysql\conf:/etc/mysql 启动
   2. 拷贝mysql容器中的my.cnf到主机中   docker cp  mysql8:/etc/mysql/conf.d E:\docker\mysql\
   3. docker rm mysql8
   4. 重新run

4. docker run -e PARAMS="--spring.datasource.url=jdbc:mysql://mysql8/xxl_job?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=root" -p 9090:8080 -v E:\docker_logs:/data/applogs --name xxl-job-admin  -d  --network xxl-job xuxueli/xxl-job-admin:2.3.0 

   127.0.0.1:3306->mysql8

   添加 --spring.datasource.username=root --spring.datasource.password=password

5. http://localhost:9090/xxl-job-admin/toLogin

补充说明：

| `--link` |                                                              | Add link to another container |
| -------- | ------------------------------------------------------------ | ----------------------------- |
|          | `--link <name or id>:alias` 其中，name和id是源容器的name和id，alias是源容器在link下的别名。 |                               |

### 配置部署执行器

1. 确认pom文件中引入了 “xxl-job-core” 的maven依赖；

2. 配置E:\xxl-job\xxl-job-executor-samples\xxl-job-executor-sample-springboot\src\main\resources\application.properties

   ```
   ### 调度中心部署根地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
   xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin
   ### 执行器通讯TOKEN [选填]：非空时启用；
   xxl.job.accessToken=
   ### 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
   xxl.job.executor.appname=xxl-job-executor-sample
   ### 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。
   xxl.job.executor.address=
   ### 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；
   xxl.job.executor.ip=
   ### 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；
   xxl.job.executor.port=9999
   ### 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
   xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler
   ### 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；
   xxl.job.executor.logretentiondays=30
   ```

   

   E:\xxl-job\xxl-job-executor-samples\xxl-job-executor-sample-springboot\src\main\java\com\xxl\job\executor\core\config

   ```
   @Bean
   public XxlJobSpringExecutor xxlJobExecutor() {
       logger.info(">>>>>>>>>>> xxl-job config init.");
       XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();
       xxlJobSpringExecutor.setAdminAddresses(adminAddresses);
       xxlJobSpringExecutor.setAppname(appname);
       xxlJobSpringExecutor.setIp(ip);
       xxlJobSpringExecutor.setPort(port);
       xxlJobSpringExecutor.setAccessToken(accessToken);
       xxlJobSpringExecutor.setLogPath(logPath);
       xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);
       return xxlJobSpringExecutor;
   }
   ```

   

2.  部署到docker上
3. 执行器集群(可选)





























# 分布式限流

 服务器1s能处理10个请求

实际: 1s有100个请求

1. 新增服务器
2. 拒绝策略
3. 排队10s



## 压测(ab)

Apache Bench 是 Apache 服务器自带的一个web[压力测试](https://link.zhihu.com/?target=https%3A//so.csdn.net/so/search%3Fq%3D%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%26spm%3D1001.2101.3001.7020)工具，简称 ab 。

ab的原理：ab命令会创建 **多个并发** 访问线程，模拟 **多个访问者** 同时对某一 **URL地址** 进行访问。

它的测试目标是基于URL的，因此，它既可以用来测试apache的负载压力，也可以测试nginx、lighthttp、tomcat、[IIS](https://link.zhihu.com/?target=https%3A//so.csdn.net/so/search%3Fq%3DIIS%26spm%3D1001.2101.3001.7020)等其它Web服务器的压力。

ab是一个命令行工具， ab命令对发出负载的计算机要求很低，它既不会占用很高CPU，也不会占用很多内存(安装到windows页没关系)



https://www.apachelounge.com/download/



**参数介绍**

```text
格式：ab [options] [http://]hostname[:port]/path

下面是参数

-n requests Number of requests to perform             //本次测试发起的总请求数
-c concurrency Number of multiple requests to make　　 //一次产生的请求数（或并发数） 模拟多人同时访问
-t timelimit Seconds to max. wait for responses　　　　//测试所进行的最大秒数，默认没有时间限制。
-r Don't exit on socket receive errors.              // 抛出异常继续执行测试任务 
-p postfile File containing data to POST　　    //包含了需要POST的数据的文件，文件格式如“p1=1&p2=2”.使用方法是 -p 111.txt

-T content-type Content-type header for POSTing
// POST 数据所使用的 Content-type 头信息，如 -T “application/x-www-form-urlencoded” 。 （配合-p）

-v verbosity How much troubleshooting info to print
//设置显示信息的详细程度 – 4或更大值会显示头信息， 3或更大值可以显示响应代码(404, 200等), 2或更大值可以显示警告和其他信息。 -V 显示版本号并退出。

-C attribute Add cookie, eg. -C “c1=1234,c2=2,c3=3” (repeatable)

//-C cookie-name=value 对请求附加一个Cookie:行。 其典型形式是name=value的一个参数对。此参数可以重复，用逗号分割。
提示：可以借助session实现原理传递 JSESSIONID参数， 实现保持会话的功能，如-C ” c1=1234,c2=2,c3=3, JSESSIONID=FF056CD16DA9D71CB131C1D56F0319F8″ 。

-w Print out results in HTML tables　　//以HTML表的格式输出结果。默认时，它是白色背景的两列宽度的一张表。
-i Use HEAD instead of GET
```

同时处理c个请求并运行n次url文件





**输出指标分析(ab->hrrp abs->https)**

![image-20220809092704657](assets/image-20220809092704657.png)

Document Path:测试页面
Document Length: 页面大小
Concurrency Level: 测试的[并发](https://link.zhihu.com/?target=https%3A//so.csdn.net/so/search%3Fq%3D%E5%B9%B6%E5%8F%91%26spm%3D1001.2101.3001.7020)数
Time taken for tests:整个测试持续的时间
Complete requests:完成的请求数量
Failed requests: 失败的请求数量

Total transferred: 整个过程中的网络传输量
HTML transferred: 整个过程中的HTML内容传输量
Requests per second: 最重要的指标之一，相当于LR中的每秒事务数，后面括号中的mean表示这是一个平均值
Time per request: 最重要的指标之二，相当于LR中的平均事务响应时间，后面括号中的mean表示这是一个平均值,代表每个链接上单个请求的平均响应时间
Time per request: 所有链接合计后单个请求的平均响应时间

​			Tpr1=Tpr2*c

Transfer rate: 平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题



测试

1. n 100

   c100 Requests per second:    19.08 [#/sec] (mean)

   c90 Requests per second:    10.32 [#/sec] (mean)

   c80 Requests per second:    11.91 [#/sec] (mean)
   c65 Requests per second:    14.87 [#/sec] (mean)
   c57 Requests per second:    16.98 [#/sec] (mean)
   c50 Requests per second:    17.88 [#/sec] (mean)
   c20 Requests per second:    15.91 [#/sec] (mean)
   c5 Requests per second:    14.47 [#/sec] (mean)
   c1 Requests per second:    4.62 [#/sec] (mean)

   并发数在1/2n附近或n为宜

2. c 50

   n800 Requests per second:    17.62 [#/sec] (mean)
   n400 Requests per second:    17.15 [#/sec] (mean)
   n200 Requests per second:    16.98 [#/sec] (mean)
   n100 Requests per second:    17.88 [#/sec] (mean)
   n50  Requests per second:    16.98 [#/sec] (mean)

   并发数一定,发现qps基本相同



**测试自己的rest Api** 

**ab无论错误有结果就会返回,需要提前先测下接口**

ab -c 50 -n 100 http://localhost:8080/leaf/segment   1601.51[#/sec] (mean) failed 0  由于step增大 qps越来越高

ab -c 100 -n 100 http://localhost:8080/leaf/segment 1501.40 [#/sec] (mean)  failed 取决于step step越小failed越大



模拟处理延迟

```
@GetMapping("/testAb")
public long testAb()  {
    Thread.sleep(500);
    return 1L;
}
```

ab -c 50 -n 100 http://localhost:8080/leaf/testAb   63.75 [#/sec] (mean)

ab -c 10 -n 100 http://localhost:8080/leaf/testAb    84.62 [#/sec] (mean)

考虑通过异步提高qps

ab -c 50 -n 100 http://localhost:8080/leaf/testAb  1990[#/sec] (mean)

ab -c 10 -n 100 http://localhost:8080/leaf/testAb   2135.57 [#/sec] (mean)







## 算法

### 自研算法

```
/**
 * 单位时间(T)内 允许最大流量 ReqMax,维护计数器Cnt
 * 请求进来,判断是否到下一个单位时间
 *      1. 否  Cnt++ 若 Cnt>ReqMax 拒绝请求
 *      2. 是  Cnt=0
 */
public static void main(String[] args) {
    final int T=5;
    final int REQ_MAX=3;
    int cnt=0;
    long startTime=System.currentTimeMillis();
    long requestTime=startTime;

    while (true){
        requestTime= requestTime+ new Random().nextInt(2*T*1000);
        if(requestTime>startTime+5000){
            cnt=1;
            startTime=System.currentTimeMillis();
            requestTime=startTime;
            System.out.println(requestTime+" 接受请求");
        }else{
            cnt++;
            if(cnt>REQ_MAX){
                System.out.println("当前cnt为 "+cnt+" ,拒绝请求");
                continue;
            }
            System.out.println(requestTime+" 接受请求");
        }
    }
```

存在的问题

在两个单位时间的临界值上的处理是有缺陷的。

第一个单位时间的最后一秒里达到的请求数为ReqMax(之前没有请求),接下来第二个单位时间T的第一秒里达到请求数也是ReqMax,由于超时重置发生在两个单位时间之间，所以这2*ReqMax个请求都将通过控制，也就是说在2s里处理2*ReqMax个请求，与我们设置的T里ReqMax个请求的设想是相违背

学术一点的说法是**该算法处理请求不够平滑**，不能很好的满足限流需求





### 漏桶算法

漏桶算法思路很简单，请求先进入到漏桶里，漏桶以固定的速度出水，也就是处理请求，当水加的过快，则会直接溢出，也就是拒绝请求，可以看出**漏桶算法能强行限制数据的传输速率**。

![img](assets/v2-a7dbe4f48d28d90b378a64a5ff19b33a_1440w.jpg)

```
//桶的容量
final long capacity=5000;
//水漏出的速率
final int rate=1;
//当前桶里的数量
long water=2000;
long prev=System.currentTimeMillis();
long now;

while (true){
    now=System.currentTimeMillis();
    //先执行漏水,(now-prev)*rate 可以看作这段时间的流出
    water=Math.max(0,water-(now-prev)*rate);
    prev=now;
    if(water<capacity){  //水还未满 加水
        water++;
        System.out.println("水还未满 加水");
    }else{
        System.out.println("水桶已满,拒绝");
    }

}
```

优点:

1. 很好的解决了时间边界处理不够平滑的问题

2. **能够强行限制数据的传输速率**

缺点:

无法处理某种程度的突发传输

###　令牌桶算法

令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。

![image-20220809144854717](assets/image-20220809144854717.png)

- 假如用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶(每秒会有r个令牌放入桶中)；
- 假设桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃
- 算法允许最长b个请求的突发，但从长期运行结果看，发送速率的速率被限制成常量r



```
//令牌桶的容量
final long capacity=5000;
//桶里令牌数
long tokens=1000;
//令牌生成速率 r/ms个
int r=300;
//每次需要获取的令牌
int tryAcquire;
//之前突发的债务
long remain=0;
long prev = System.currentTimeMillis();
long now;

while (true){
    now=System.currentTimeMillis();
    tryAcquire=1+new Random().nextInt((int)(capacity*1.9));
    //先获取令牌
    tokens=Math.min(capacity,tokens+remain+(now-prev)*r);
    prev=now;
    if(tokens>=0){
        if(tryAcquire<=tokens){
            tokens-=tryAcquire;
            System.out.println(tryAcquire+" 正常获取 tokens: "+tokens);
        }
        else if(tryAcquire<=tokens+capacity) {//允许突发
            remain=tokens-tryAcquire;
            tokens=0;
            System.out.println(tryAcquire+" 允许突发,突发了 "+remain);
        }else{
            System.out.println("请求量太大,不允许突发 "+tryAcquire+" 作废");
        }
    }else{
        System.out.println("等待速率整型");
        Thread.sleep(-tokens/r);
        tokens=0;
        remain=0;
    }

}
```







## 限流工具包 RateLimiter

**单机版限流**

google开源工具包guava提供了限流工具类RateLimiter，该类基于“**令牌桶算法**”，非常方便使用。RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率。它支持两种获取permits接口，一种是如果拿不到立刻返回false，一种会阻塞等待一段时间看能不能拿到。

```
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>30.0-jre</version>
</dependency>
```



1. 创建令牌桶

   **初始化令牌1**

   ```
   RateLimiter limiter = RateLimiter.create(3);//permitsPerSecond
   ```

2. 获取令牌

   - ```
     //平滑输出
     log.info("{}",limiter.acquire()); 0.0
     log.info("{}",limiter.acquire()); 0.33
     ```

   - ```
     //允许突发
     log.info("{}",limiter.acquire(4)); 0.0
     log.info("{}",limiter.acquire()); 1.33=(4-1)*1/3+1/3		
     ```

```
log.info("{}",limiter.acquire(4)); //0.0
log.info("{}",limiter.acquire(6)); //1.33
log.info("{}",limiter.acquire()); //2.33
```

总结: 后者时间=前者复发债务+1/r



- ```text
  //以非阻塞的形式达到降级
  //可以实现 1+permitsPerSecond个秒杀效果(高并发下)
  if(limiter.tryAcquire()) { //未请求到limiter则立即返回false
      doSomething();
  }else{
      doSomethingElse();
  }
  ```







# 分库分表

# 分布式事务

