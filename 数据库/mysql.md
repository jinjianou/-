# 安装(windows)

1. <https://dev.mysql.com/downloads/mysql/>   注意dbforge版本要跟mysql版本对应 2019 -> 8.2.23

2. 配置在my.ini （没有复制在my_default.ini )添加

    basedir  default-character-set = utf8（[client]下），character_set_server = utf8 

   ```
   # For advice on how to change settings please see
   # http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html
   # *** DO NOT EDIT THIS FILE. It's a template which will be copied to the
   # *** default location during install, and will be replaced if you
   # *** upgrade to a newer version of MySQL.
   [client]
   default-character-set = utf8mb4
   [mysql]
   default-character-set = utf8mb4
   [mysqld]
   character-set-client-handshake = FALSE
   character-set-server = utf8mb4
   collation-server = utf8mb4_bin
   init_connect='SET NAMES utf8mb4'
   # Remove leading # and set to the amount of RAM for the most important data
   # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.
   innodb_buffer_pool_size = 128M
   # Remove leading # to turn on a very important data integrity option: logging
   # changes to the binary log between backups.
   # log_bin
   # These are commonly set, remove the # and set as required.
   basedir = D:\MySQL
   datadir = D:\MySQL\data
   port = 3306
   # server_id = .....
   # Remove leading # to set options mainly useful for reporting servers.
   # The server defaults are faster for transactions and fast SELECTs.
   # Adjust sizes as needed, experiment to find the optimal values.
   join_buffer_size = 128M
   sort_buffer_size = 16M
   read_rnd_buffer_size = 16M 
   sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
   ```

3. 初始化 ，mysqld --initialize-insecure --user=mysql

4. 安装mysql服务  mysqld --install "MySql80" --defaults-file="C:/Program Files/mysql-8.0.27-winx64/mysql-8.0.27-winx64/my.ini"

5. 启动服务 net start mysql

6. 初始密码在data文件夹下 .err文件 搜temp

7. 修改密码ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'root'; 

## 忘记密码重置

- \1. 关闭正在运行的 MySQL 服务。
- \2. 打开 DOS 窗口，转到 mysql\bin 目录。
- 输入 mysqld --skip-grant-tables 回车 
- \4. 再开一个 DOS 窗口（因为刚才那个 DOS 窗口已经不能动了），转到 mysql\bin 目录。
- \5. 输入 mysql -uroot回车，如果成功，将出现MySQL提示符 >。
- \6. 连接权限数据库： use mysql; 。
- \6. 改密码：alter user 'root'@'localhost' identified by 'root'; 
- \7. 刷新权限（必须步骤）：flush privileges;　
- \8. 退出 quit。
- \9. 注销系统，再进入，使用用户名 root 和刚才设置的新密码 123 登录。

如果mysqld启动失败则

2、初始化设置

输入：mysqld --initialize-insecure --user=mysql

 

3、创建服务

输入： mysqld --install mysql

 

4、启动服务

输入： net start mysql

## 有密码重置

mysql8 修改密码:

1.先登入 mysql -uroot -p123456

2.ALTER USER 'root'@'localhost' IDENTIFIED WITH MYSQL_NATIVE_PASSWORD BY '新密码'; 



# 基本操作

* 写锁 lock Tables tb write; unlock tables;  读写都堵塞

  读锁 lock Tables tb write; unlock tables;  写堵塞  读ok

* DEFAULT CHARACTER SET utf8 和 charset utf8一样都是设置字符集

* 导入 

  * 外部 mysql -uroot -proot < test.sql
  * 内部 source E:\test.sql

* 临时表 create temporary table ... 连接中断时自动删除

* if(expression,A,B) if expression is true then A otherwise B

  ifnull(expression,A) if expression is nullthen A otherwise expression

* limit start,count  从start开始(起始0),取count条  如果从0开始，可省略为limit count  

* RAND() return [0,1.0) 浮点数

  RAND(N) N相同则结果相同 可重复的随机数列

* AUTO_INCREMENT=N 表示 下一个自增键的值

* MySQL默认情况下是否区分大小写,使用show Variables like '%table_names'查看lower_case_table_names的值,0代表区分,1代表不区分。 

* mysql语句执行顺序

  (1)from

  (2) on

  (3) join

  (4) where

  (5)group by(开始使用select中的别名，后面的语句中都可以使用)

  (6) avg,sum....

  (7)having

  (8) select

  (9) distinct

  (10) order by

* truncate delete drop区别

  1.delete会将删除操作作为事务记录到日志中保存，以便回滚

  2.truncate 直接删除，不能回复，且不会激活触发器

  3.truncate 表和索引所占空间恢复到初始大小(table)  delete则不会  drop 释放表所占的所有空间(table& view)

  4.foreign key约束 所引用的表，不能使用truncate 应该使用delete通过级联删除数据

* using

  using 相当于 join 的on操作

  

  SELECT * from test t1 join test_copy1 tp1 on t1.id=tp1.id;

  SELECT * from test t1  join test_copy1 tp1 USING(id);

* 存储过程

  -- 定义一个存储过程
  -- found_rows() 返回结果的条数
  create procedure myPro01(in name varchar(3),out num int)
  begin
  	if name is null or name="" then
  		select * from `user`; 
  	else 
  		select * from `user` where name2 like concat('%',name2,'%');
  	end if;
  	select found_rows() into num; 
  end;

  call myPro01(null,@num);
  select @num;

  

  DELIMITER $$
  CREATE PROCEDURE add_stus(IN num int)
  BEGIN 
  	DECLARE i int DEFAULT 0;
  	DECLARE _birthday datetime;
  	WHILE num>i DO    
  		SET _birthday  = date_sub(now(),INTERVAL floor(RAND()*1000) day);    		INSERT INTO stu SET 
  		sname = concat(left(md5(RAND()),5),'后盾人向军'), 
  		class_id =1+FLOOR( RAND()*100000), 
  		birthday = _birthday , 
  		sex = 1+FLOOR(RAND()*2 );    
  	

  ​		SET i=i+1;

  ​	END WHILE;

  end $$
  DELIMITER ;

* 枚举值 alter table user add sex enum('男','女')

  ​	可以从索引或值开始检索/添加 索引从1开始

  set与enum相似，但同时可以存在多个值

  ​	alter table user add collection set ('a','b')

  ​        检索：

  ​	select * from user where find_in_set('b',collection) 
  ​	select * from user where collection like '%b%' 



## 表操作

* 修改表名 alter table tbname rename tbname2

* 修改表字符集 alter table tbname charset gbk

*  修改字段类型 alter table tbname  modify  field ....

*  修改字段类型+名称 alter table tbname  change field new_field ....

* 调整字段顺序 alter table user modify id int auto_increment after/before name2  

  ​	 first/last(新增时默认)	

* 对于具备自增属性的主键，在删除主键之前需要删除自增属性

  ​	there can be only one auto column and it must be defined as a key  只能有一个自增列并且被定义为key

  alter table user modify id int not null;
  alter table user drop primary key;

  alter table user add primary key(id)

* 

## 校对规则

字符比较和排序的规则

_ci case insensitive 

cs: case sensitive，大小写敏感，区分大小写比较 

 _bin 使用二进制比较 ,区分大小写

​	_general_ci 速度快  _unicode_ci 准确性高 

修改表校对规则只对新增字段有影响

查看校对规则 

​	show table status from dbname like '%tbname%'

​	show collation like '%utf8%'

修改 alter table tbname   modify field  varchar(30)  collate 'utf8_bin'



**mysql排序默认null最小**



# 函数



## 字符串

mid(field,start,count)  start从1开始 截取字串

substring(field,start)  start从1开始 向右截取

char_length(str) 字符数量而非字节数

​	char/varchar 对于unicode字符算个数（即ascii和汉字等同）

replace(field,old_str,new_str) 全部替换

## 正则表达式

select * from user where name2 regexp '^a'

like %任意字符串 _任意一个字符



# 数据类型

* tinyint(m) 1个字节 unsiged => (0,256)    **tinyint unsiged 而不是unsiged  tinyint** 

		m代表最小显示位数 需要配合zerofill使用生效

		alter table user add column age int(3) unsiged zerofill 
		
		smallint  2个字节
		
		mediumint  3个字节
		
		int 4个字节
		
		bigint 8个字节

* float/double计算   V=(-1)^s*(1+f)*2^e

  f尾数 （小数）部分  23位  max 1-2^-23

  e指数部分 8位   -128~127 

  vmax=(1+1-2^-23)*2^127~=2^128

* DateTime 8bytes 1000-01-01~9999:12-31

  Timestamp 4bytes 1970-01-01:2038-01-19

  会话时区设置 set time_zone='+8:00'

  全局时区设置 set global time_zone='+8:00';flush privileges; 

  ​	//将**当前user和privilige表中的用户信息/权限设置从mysql库** (MySQL数据库的内置库)中提取到内存里。 MySQL用户数据和权限有修改后，希望在"不重启MySQL服务"的情况下直接生效，那么就需要执行这个命令 

  ![1](C:\Users\Administrator\Desktop\复习\素材\pic\sql\1.jpg)

  ![1](C:\Users\Administrator\Desktop\复习\素材\pic\sql\2.jpg)

  curdate() == current_date()

  

  select timestampdiff(day,'1992-01-01',current_timestamp) 第三个参数-第二个参数

  ​	year/month/day/hour/minute/second

  ​	mysql中日期可用字符串或数字表示 如 19920101000000



```
SELECT DATE_ADD(now(),INTERVAL 7 DAY);
SELECT DATE_ADD(NOW(),INTERVAL '20:10' HOUR_MINUTE);
SELECT DATE_ADD(NOW(),INTERVAL '2 8' DAY_HOUR);
```

# 视图

视图（view)是从单张或多张表或其他视图构建出来的**虚拟表** 数据库中只存放视图的**定义**，而不存放视图中的数据，数据由引用视图时动态产生

* Create [or replace] view view_name

  as

  select statement

  [with check option] //检查update操作是否符合select statement过滤条件

* 对视图的crud 本质上是对涉及表的操作

* 

# 运行模式

查看 select @@sql_mode

![4](C:\Users\Administrator\Desktop\复习\素材\pic\sql\4.jpg)

NO_ENGINE_SUBSTITUTION: 当sql_mode中包涵no_engine_subtitution时，如果create table 时指定的engine项不被支持，这个时候mysql会支持**报错**。 不包含no_engine_subtitution 会替换为 innodb

**常用模式是系统将不同的模式选项过行的组合**

| 模式        | 说明                                                         |
| ----------- | ------------------------------------------------------------ |
| ANSI        | 宽松模式：对长度超过字段定义等错误进行截取等操作。报WARNING警告错误 |
| TRADITIONAL | 严格模式：对数据进行严格校验。事务处理中会进行事务回滚操作。非事务时，发生错误时就立即报错终止，会造成有部分数据插入。 |

设置当前会话为宽松模式  set session sql_mode=ANSI; 或者 SET GLOBAL sql_mode='';

**ONLY_FULL_GROUP_BY要求SELECT中的字段是在与GROUP BY中使用的字段**

- 如果GROUP BY 是主键或UNIQUE NOT NULL时可以在SELECT中列出其他字段
- 使用max/min/avg/count 等聚合函数时不受ONLY_FULL_GROUP_BY模式影响

select sex,**any_value**(name2),count(1) from user group by sex 

//any_value会读取使用group by分组后的每组中第一个数据  count(1) 仍是分组的数据

	### 聚合函数

```
SELECT * FROM stu ORDER BY RAND() LIMIT 1; //随机获取一条记录
SELECT FIELD('a','c','a','b'); a是比较字符 之后的是需要比较的集合 返回比较字符在集合中的索引（从1开始）不存在返回0
where (name2,sex) in (select name2,sex from user)  //多个条件查询

```

# 多表

`UNION` 用于连接多个查询结果，要保证每个查询返回的列的数量与顺序要一样。

- UNION会过滤重复的结果
- UNION ALL 不过滤重复结果
- 列表字段由是第一个查询的字段

**多表删除**

​	多表删除是指从一个或多个表中删除满足条件的数据，想对表使用别名，则只能在 table_references子句中使用，否则会报错 

​	delete t1,t2 from user t1 inner join user3 t2 where t1.user3_id=t2.id

​	

# 外键

外键表示一个表中的字段被另一个表中的一个字段引用。外键对相关表中的数据造成了限制，使MySQL能够保持数据完整性。 

- 父表和子表储存引擎要一致
- 使用InnoDB引擎支持外键约束
- 外键要与主表列类型一致
- 外键列使用索引（有些版本的mysql会自动帮助为外键设置索引)

新增外键： 

​	[ADD] CONSTRAINT stu_classFOREIGN KEY (class_id) REFERENCES class(id) \[ON DELETE SET NULL][ON UPDATE CASCADE];

删除外键： ALTER TABLE stu DROP FOREIGN KEY stu_class;

## 处理动作

ON DELETE指在删除时的处理方式，常用的处理方式包括以下几种。

| 选项                                             | 说明                                                         |
| ------------------------------------------------ | ------------------------------------------------------------ |
| ON DELETE CASCADE                                | 删除父表（被引用的）记录时，子表记录同时删除（引用的)        |
| ON DELETE SET NULL                               | 删除父表记录时，子表记录设置为NULL（子表字段要允许NULL）     |
| ON DELETE NO ACTION 、ON DELETE RESTRICT（默认） | 当在父表（即外键的来源表）中 删除 对应记录时，首先检查该记录是否有对应外键，如果有则不允许 删除 |

ON UPDATE 指在更新时的处理方式，常用的处理方式包括以下几种。

| 选项                                            | 说明                                                         |
| ----------------------------------------------- | ------------------------------------------------------------ |
| ON UPDATE CASCADE                               | 更新父表记录时，比如更改主表的主键时，子表记录同时更新       |
| ON UPDATE SET NULL                              | 更新父表记录时，比如更改主表的主键时，子表记录设置为NULL     |
| ON UPDATE NO ACTION /ON UPDATE RESTRICT（默认） | 当在父表（即外键的来源表）中 增加 对应记录时，首先检查该记录是否有对应外键，如果有则不允许 增加 |

# <u>事务</u>

事务是保证多个**SQL操作的一致性**，如果一条失败全部SQL也将失效。 

查看引擎 SHOW ENGINES; ALTER TABLE stu ENGINE=InnoDB;

![5](C:\Users\Administrator\Desktop\复习\素材\pic\sql\5.jpg)

##  隔离级别

* Mysql的提交默认是自动提交  

			关闭/开启 SET AUTOCOMMIT = 0; SET AUTOCOMMIT = 1;

* 事务提交

			执行 `START TRANSACTION` 或 `BEGIN` 语句后，表示要开启一项事务处理。 

			COMMIT 提交事务
		
			ROLLBACK 回滚事务

* 事务并发可能出现的情况：

			脏读: 一个事务读到了另一个未提交事务修改过的数据 

			不可重复读: 一个事务只能读到另一个已经提交的事务修改过的数据，并且**其他事务每对该数据进行一	次修改并提交后，该事务都能查询得到最新值**。
		
			幻读：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中**插入**了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。

* 对应的就会产生以下隔离级别

			读未提交（read-uncommitted） 

			不可重复读（read-committed） 
		
			可重复读（repeatable-read）:在可重复读隔离级别下，事务B只能在事务A修改过数据并提交后，**自己也提交事务后，才能读取到事务B修改的数据**。 
		
			串行化（serializable）  
		
			查询/设置隔离级别 
		
				select @@global.transaction_isolation,@@transaction_isolation;	 
		
				 set session|global transaction isolation level read committed;
		
			为什么上了写锁（写操作），别的事务还可以读操作？
		
				因为InnoDB有MVCC机制（多版本并发控制），可以使用快照读，而不会被阻塞 **版本号** 

# 锁

因为Mysql支持多线程方式，所以可以同时处理多个客户端请求。有时为了防止客户端同时修改数据，我们使用锁操作完成。 

`InnoDB` 是主流储存引擎并支持行级锁的 

- 行锁开销大，锁表慢
- 行锁高并发下可并行处理，性能更高
- 行锁是针对索引加的锁，在通过**索引检索**时才会应用行锁，否则使用**表锁**（有索引用行锁，没有用表锁）
- 在事务执行过程中，随时都可以执行锁定，**锁在执行 COMMIT或者ROLLBACK的时候释放**

范围锁 **没有指定明确范围时也会造成大量记录的锁定**  where id>2 and id<5  锁定（2,5）行记录

悲观锁  指对数据被外界修改持保守态度，**在整个数据处理过程中，将数据处于锁定状态**

​	BEGIN;
​	SELECT * FROM user WHERE id=2 FOR UPDATE;
​	UPDATE user SET name2='x' WHERE id=2; 

mysql中都是悲观锁

乐观锁 每次去拿数据的时候认为别人不会修改，**不对数据上锁，但是在提交更新的时候会判断在此期间数据是否被更改**，如果被更改则提交失败。  **版本号**  读取不上锁,提交更新时判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对 ，不一致就执行失败

​	实现：

​		先读表的数据，得到version的值为versionValue 

​		update table set value=newValue,version=versionVaule+1 where version=versionVaule

以下都是悲观锁：

|                    | 当前事务   | 其他事务                            | 例子                                                         |
| ------------------ | ---------- | ----------------------------------- | ------------------------------------------------------------ |
| 共享锁（读锁 S锁） | 可读不可写 | 能读（即加S锁），不可写（即加X锁）  | LOCK TABLE goods READ，stu READ;  select ... lock in share mode; |
| 排它锁   (写锁)    | 可读可写   | 不可读（即加S锁）,不可写（即加X锁） | for update(行级锁)                                           LOCK TABLE goods WRITE，stu WRITE; |

# 索引

索引就像一本书的目录一样，我们可以通过一本书的目录，快速的找到需要的页面，但是我们也不能过多的创建目录页（索引），原因是如果某一篇文章删除或修改将发变所有页码的顺序，就需要重新创建目录。 

## 基础思路

**选择合理范围内最小的**

我们应该选择最小的数据范围，因为这样可以大大减少磁盘空间及磁盘I/0读写开销，减少内存占用，减少CPU的占用率。

**选择相对简单的数据类型**

数字类型相对字符串类型要简单的多，尤其是在比较运算是，所以我们应该选择最简单的数据类型，比如说在保存时间时，因为PHP可以良好的处理LINUX时间戳所以我们可以将日期存为int(10)要方便、合适、快速的多。



## 字符串

字符串数据类型是一个万能数据类型，可以储存数值、字符串等。

保存数值类型最好不要用字符串数据类型，这样存储的空间显然是会更大，而且在排序时字符串的9是大于22的。如果进行运算时mysql会将字符串转换为数值类型，这种转换是不会走索引的。

如果明确数据在一个完整的集合中如男，女，那么可以使用set或enum数据类型，这种数据类型在运算及储存时以数值方式操作，所以效率要比字符串更好，同时空间占用更少

## 数值类型

**整数**

整数类型很多比如tinyint、int、smallint、bigint等，那么我们要根据自己需要存储的数据长度决定使用的类型，同时tinyint(10)与tinyint(100)在储存与计算上并无任何差别，区别只是显示层面上，但是我们也要选择适合合适的数据类型长度。可以通过指定zerofill属性查看显示时区别。

**浮点数与精度数值**

浮点数float与double在储存空间及运行效率上要优于精度数值类型decimal，但float与double会有舍入错误而decimal则可以提供更加准确的小数级精确运算不会有错误产生计算更精确，适用于金融类型数据的存储。

**总结** **数值数据类型**要比字符串执行更快，**范围区间小的数据类型**占用空间更少，处理速度更快，如tinyint可比bigint要快的多。 选择数据类型时要考虑内容长度，比如是保存毫米单位还是米而选择不同的数值类型

decimal(P,D) P是有效数字精度,D是小数位数

 MySQL使用二进制格式存储`DECIMAL`值。它将`9`位数字包装成`4`个字节

| 0    | 0    |
| ---- | ---- |
| 1–2  | 1    |
| 3–4  | 2    |
| 5–6  | 3    |
| 7-9  | 4    |

如decimal(19,9) 小数位9位 4个字节;整数部分10位,4+1(查表),所以总共要9个字节存储



**索引弊端**

- 创建索引会使查询操作变得更加快速，但是会降低增加、删除、更新操作的速度，因为执行这些操作的同时会对索引文件进行重新排序或更新
- 创建过多列的索引会大大增加磁盘空间开销
- 不要盲目的创建索引，只为查询操作频繁的列创建索引

## 索引类型

* UNIQUE唯一索引  不可以出现相同的值，可以有NULL值 
* INDEX普通索引  允许出现相同的索引内容 
* PRIMARY KEY主键索引  不允许出现相同的值，且不能为NULL值 

## 数据结构分析

[图灵诸葛老师MySQL视频教程全集，MySQL数据库优化+MySQL索引优化（2022最新版）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1D44y1Y79z?p=1&vd_source=694ae2fa63787dd0c86c0c90c56dd2e0)

![image-20220727161348917](.\mysql.assets\image-20220727161348917.png)

1. 无数据结构  需要经过n次io
2. 二叉树（binary tree）是指树中节点的**度不大于2**的**有序**树 

二叉查找树（binary search tree）

若它的左子树不空，则左子树上所有结点的值均小于它的 根结点 的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；

```
自增键的话 退化成链表 o(n)
```



2. 红黑树 **红黑树其实就是去除二叉查找树顶端优势的解决方案**，从而达到树的平衡 

Red-Black Tree 「RBT」是一个自平衡(不是绝对的平衡)的二叉查找树(BST) 

 1. 每个节点都有红色或黑色 

 2. 树的根始终是黑色的 每个叶节点都是不存储数据的黑色空节点

 3. 没有两个相邻的[红色节点](https://www.zhihu.com/search?q=%E7%BA%A2%E8%89%B2%E8%8A%82%E7%82%B9&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A79980618%7D)（红色节点不能有红色父节点或红色子节点，**并没有说不能出现连续的黑色节点**） 

 4. 任意节点到其可到达的叶节点间都具有相同数量的黑色节点 

    

    变色&旋转

    旋转

    * 左旋

      x左旋 让x的右节点y成为x的父节点（调整后x是y的左子树），让**y**的左子树成为x的右子树 

    * 右旋

    - x右旋 让x的左孩子y成为新的父节点（调整后x是y的右子树），让y的右子树成为x的左子树

步骤:

1. 插入 与二叉查找树相同 插入节点且颜色红色
2. 修复

* z是根节点（插入前是空树） 红色->黑色

* z的叔节点是红色的

  ​	将 parent 和 uncle 标记为黑色 

  ​	将 grand parent (祖父) 标记为红色 

* z的叔节点是黑色的，且局部呈现直线

  ​	z zparent  zgrand parent在一条直线上

  ​	1. 右边的直线左旋 左边的直线右旋 对 zgrand parent旋转

   2. z原来的parent 和grand parent变色

      3.根节点变黑色

* z的叔节点是黑色的，且局部呈现三角形

   zparent  zgrand z叔结点构成了一个三角形

  1. z的父节点右旋
  2. 参照情况三旋转

		**当索引列数据量很大时，由于红黑树高度不可控（会变得很大,如id），mysql没使用红黑树**

* AVL

  平衡[二叉树](https://so.csdn.net/so/search?from=pc_blog_highlight&q=%E4%BA%8C%E5%8F%89%E6%A0%91)的定义是一种递归定义，要求每个节点都具有以下特性：

  1. 可以是一棵空树
  2. 左子树和右子树高度之差的绝对值不超过1（左右子树的高度差可以为0、1和 -1）
  3. 左子树和右子树均为平衡二叉树

* B tree

  平衡的**多路**（多叉）搜索树，多用于文件系统，数据库实现

  高度平衡 每个节点的所有子树高度一致

  m阶b树 节点存储的元素个数最多时m-1个   根节点最少1个 非根节点最少ceil(m/2)-1个

  * 添加

    新添加元素必定是添加到叶子节点

    可能出现上溢的问题（上节点的元素个数必然等于m）

    1. 设上溢节点最中间的位置为k
    2. 将k位置的元素向上与父节点合并
    3. 将[0,k-1]和[k+1,m-1]元素分别分裂成节点
    4. 递归处理父节点上溢问题![6](C:\Users\Administrator\Desktop\复习\素材\pic\sql\6.jpg)

  * 删除

    叶子节点直接删除 考虑下溢问题

    非叶子节点元素 0.找到要删除的结点 1.找到该节点的前驱（小于它的最大值）或 后继(大于它的最小值)，覆盖删除的元素  2.将前驱或 后继删除

    3.下溢解决方案（递归解决）：

    * 如果兄弟节点有至少ceil(m/2)个元素 则将b->右子树最小的位置 a->b原来的位置

    * 如果兄弟节点只有ceil(m/2)-1个元素 将b拿下来跟左右节点合并

      ![7](C:\Users\Administrator\Desktop\复习\素材\pic\sql\7.jpg)

* **Hash**

  由于**不支持范围查找** 比如id>10只能全部遍历 **适用不用范围查找的字段**

  ![12](..\素材\pic\sql\12.jpg)

* **B+tree**

  中间节点 不保存数据，只用来索引，所有数据都保存在叶子节点 

  中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素 

  所有的叶子结点中包含了全部索引的信息，及指向含这些索引的记录的指针(即索引所在行的内存地址)，且叶子结点本身依关键字的大小顺序链接（双向指针）。 

  1. 性能分析

     B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；

     Innodb为了减少磁盘i/0，引入了预读的概念，单位是页（数据都是存储在页中）,**最小存储单元**

     show variables like 'innodb_page_size'; //默认16kB

     

     

     ![9](C:\Users\Administrator\Desktop\复习\素材\pic\sql\9.jpg)

     ![11jpg](C:\Users\Administrator\Desktop\复习\素材\pic\sql\11jpg.jpg)

     

     假设一个数据节点（叶子节点) 1kB  16条记录

     目录页中一个页号数据节点是 14B =8B(索引 bigint)+6B(磁盘文件地址) 能存 1170条

     两次IO 最多16*1170=18720个数据

     三次IO  最多16*1170  *1170 =2190w个数据

     而且b+ tree **mysql启动时会将第一层和第二层的目录加入到缓存中**(预读)（比如三层目录只要将叶子节点加载到内存一次I/O,四层目录只需要2次IO）

  2. 数据表文件组织方式

  

  ```mysql
  table salary(
  	id int not null auto_increment primary key,
  	name varchar(50) not null default '', 
  	salary varchar(50) not null default '', 
  	key name(name)
  )engine=innodb|MyIsam,charset utf8;
  
  insert into salary(id,name,salary) values(10,'mly10',100),(5,'mly5',500),
  (7,'mly7',700),(1,'mly1',100);
  
  show variables like '%datadir%'; /var/lib/mysql/
  cd btree //进入到对应库中
  ```

  

  myIsam  索引文件和数据文件分开 MYI  MYD(非聚集)

  innodb   索引和数据在idb文件中(聚集)

  

  ![8](C:\Users\Administrator\Desktop\复习\素材\pic\sql\8.jpg)

  

3. 索引类型

* 聚集(聚簇)索引 innodb的索引方式(MYISAM用的就是非聚集索引,需要回表)   的叶子结点存储索引字段值和表中其他字段值(也就是完整的数据记录)

  * 主键索引

  * 普通索引（次级索引）非主键索引 叶子节点存储的主键id(一致性和节省存储空间)

    需要拿主键再进行一次主键索引查找(回表)

<<<<<<< HEAD


  数据库索引是存储在磁盘上的，如果数据量很大，必然会导致索引的大小也会很大，超过几个G;

  当我们用索引查询的时候，是不可能将几个G的索引都加载到内存中的，我们能做的只能是只能是

  **每次I/0加载相应的磁盘页**

  * 普通索引（次级索引） 叶子节点会存储主键id
=======
>>>>>>> 0e3a448f65e92dd247e813debe34ea40db4b4e88


![10](C:\Users\Administrator\Desktop\复习\素材\pic\sql\10.jpg)

尽量用索引覆盖，由于回表（通过主键id）的磁盘空间不连续，就可能会产生磁盘的随机io



为什么建议建主键，且整型自增?

如果不建，数据库会找一个可以建unqiue索引的列来维护B+树索引结构来组织数据库记录（不存在unqiue 自增隐藏类似rowid的列） 提高性能

整型 比较效率高 且减少硬盘消耗

自增 防止节点[上溢]分裂导致的性能开销

* 联合索引 从左往右排序

![13](C:\Users\Administrator\Desktop\复习\素材\pic\sql\13.jpg)

## Explain

* id 索引执行顺序 

  id相同,执行顺序由上至下<br>id不同,id值越大,优先级越高,越先被执行

  id为null,最后执行

* select_type 查询类型

  simple:查询中不包含子查询或union查询<br>

  union:UNION操作中，查询中处于内层的SELECT

   DEPENDENT UNION：UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句有依赖关系）

  union result:union的结果，id值通常为NULL<br>

  MATERIALIZED：被物化的子查询(exists,in)

   derived 在from列表中包含的子查询 子查询中用到的表<br> primary:查询中若包含任何复杂的子部分,最外层查询则被标记为     						primary

   subquery 在select 或where 列表中包含了子查询

* table 操作表

* type  使用类型  查询类型从最好到最差依次是:system>const>eq_ref>ref>range>index>All,一般情况下,得至少保证达到range级别,最好能达到ref 

   system:表只有一行记录,这是const类型的特例,平时不会出现
   const:表示通过索引一次就找到了,const即常量,它用于比较primary key或unique索引,因为只匹配一行数据,所以效率很快,如将主键置于where条件中,mysql就能将该查询转换为一个常量

   (一般是单表)

   eq_ref:唯一性索引扫描,对于每个索引键,表中只有一条记录与之匹配,常见于主键或唯一索引扫描(一般是关联表)

   ref:非唯一性索引扫描,返回匹配某个单独值的行,它可能会找到多个符合条件的行,所以他应该属于查找和扫描的混合体

   range:只检索给定范围的行,使用一个**索引**来选择行,如where语句中出现了between,<,>,in等查询,这种范围扫描索引比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引

   index类型只遍历索引树,这通常比All快,因为索引文件通常比数据文件小,index是从索引中读取,all从硬盘中读取(需要回表,跟all一样都是取得了全表的数据)

   all:全表扫描,是最差的一种查询类型

   **至少需要range级别**

* possible_keys  可能用到的索引，不一定被真正使用

  显示可能应用在这张表中的索引,一个或多个,查询到的索引不一定是真正被用到的 

* key    最终使用的索引

  实际使用的索引,如果为null,则没有使用索引

* key_len 索引字节数   

  表示索引中使用的字节数,而通过该列计算查询中使用的 索引长度,在不损失精确性的情况下,长度越短越好,key_len显示的值为索引字段的最大可能长度,并非实际使用长度

* ref  列与索引的比较

   显示索引的哪一列被使用了,如果可能的话是一个常数,哪些列或常量被用于查找索引列上的值

* rows  预计读出的记录条数

    根据表统计信息及索引选用情况,大只估算出找到所需的记录所需要读取的行数

* fielted

  Percentage of rows filtered by table condition 

  这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比 

* Extra  查询说明   

  Using filesort:说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取,mysql中**无法利用索引完成的排序**操作称为"文件排序"
  Using temporary :使用了临时表保存中间结果,mysql在对查询结果排序时使用临时表,常见于order by和分组查询group by
  Using index:表示相应的select操作中使用了覆盖索引（Covering Index），避免访问了表的数据行，效率不错。如果同时出现using where，表明索引被用来执行索引键值的查找；如果没有同时出现using where，表明索引用来读取数据而非执行查找动作。 其中的覆盖索引含义是所查询的列是和建立的索引字段和个数(**包含主键**)是一一对应的
  Using where:表明使用了where过滤

  Using join buffer:表明使用了连接缓存,如在查询的时候会有多次join,则可能会产生临时表
  impossible where:表示where子句的值总是false,不能用来获取任何元祖

  select tables optimized away :在没有GROUPBY子句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 

  distinct :优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作 

  

  key(title,author)

  ```mysql
  explain select t1.title, t1.author from t_vue t1  where t1.title='jin1'; //ref Using index
  explain select t1.title, t1.author from t_vue t1  where author='jin' ; // index  Using where; Using index
  explain select t1.author from t_vue t1  where author='jin' ; // index  Using where; Using index
  explain select t1.title, t1.author,t1.img from t_vue t1  where t1.title='jin1'; //all Using where
  explain select t1.*  from t_vue t1  where t1.title='jin1' and author='jin'  //ref
  
  ```

  

* 新增/删除索引 

  alter table user2 add unique|index remark_mul (remark)

  alter table user2 drop key|index remark_mul

* 查看表索引

  ```
  show index from stu;
  ```

* 强制使用索引

  explain select id,name from test  **force index(ind_test_name)** where id=1  and name='2' 

* 维度

  - **数据列中不重复值出现的个数**，维度的最大值是数据行的数量
  - 如数据表中存在8行数据a ,b ,c,d,a,b,c,d这个表的维度为4
  - 要为维度高的列创建索引
  - 性别这样的列不适合创建索引，因为维度过低

* 索引规则

  - 对where，on或group by 及order by 中出现的列使用索引
  - 对较小的数据列使用索引，这样会使索引文件更小，同时内存中也可以装载更多的索引键
  - 为较长的字符串使用前缀索引
  - 不要过多创建索引，除了增加额外的磁盘空间外，对于DML操作的速度影响很大

* 前缀索引

  大使用text/长varchar字段时创建索引，会造成索引列长度过长，从而生成过大的索引文件影响检索性能。使用前缀索引方式进行索引，可以有效解决这个问题。前缀索引应该控制在一个合适的点，控制在0.31黄金值即可。 

  ```
  select count(distinct(left(title,Count)))/count(*) from news 
  以较小的Count（相比字段长度而言）获取到越接近0.75的索引选择性
  count(distinct(left(title,Count))) title字段前count位前缀的不同数量
  ```

  ```
  ALTER TABLE article ADD INDEX title(title(10));  
  ```

* 组合索引

  前面字段没出现，只出现后面字段时不走索引

##  表关联算法

### 嵌套循环连接 Nested-Loop Join(NLJ) 算法 （NLP）

​	一次一行循环地从第一张表（称为**驱动表**）中读取行，在这行数据中取到关联字段，根据关联字段在另一张表（**被驱动表**）里取出满足条件的行，然后取出两张表的结果合集。 

**一般 join 语句中，如果执行计划 Extra 中未出现 Using join buffer 则表示使用的 join 算法是 NLJ。** 

- 当使用left join时，左表是驱动表，右表是被驱动表  

-  当使用right join时，右表时驱动表，左表是被驱动表  

-  当使用join时，mysql会选择数据量比较小的表(参与计算的表的数 ,按照各自的条件过滤 后

  )作为驱动表，大表作为被驱动表。

- 写多表连接sql时如果明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间. （慎重）

  `select * from t2 straight_join t1 on t2.a = t1.a;` 代表指定mysql选着 **t2 表作为驱动表** 

驱动表n1条记录，被驱动表n2（有索引）  共需扫描O(n1)

**如果被驱动表的关联字段没索引，使用NLJ算法性能会比较低 ，mysql会选择Block Nested-Loop Join算法。** 

​	内存中计算速度更快

## 基于块的嵌套循环连接 Block Nested-Loop Join（BNJ）

 把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比 

驱动表n1条记录，被驱动表n2（无索引）  共需扫描O(n1*n2



如果放不下驱动表的所有数据话，策略很简单，就是**分段放**。 比如 t2 表有1000行记录， join_buffer 一次只能放800行数据，那么执行过程就是先往 join_buffer 里放800行记录，然后从 t1 表里取数据跟 join_buffer 中数据对比得到部分结果，然后清空 join_buffer ，再放入 t2 表剩余200行记录，再次从 t1 表里取数据跟 join_buffer 中数据对比。

join_buffer 的大小是由参数 **join_buffer_size** 设定的，默认值是 256k。 





## 查询优化

* 解析器 非常智能 ，决定是否使用索引或是否进行全表扫描 

  ```
  select * from houdunwang where false   //不会操作任何表或索引
  ```

* 索引列参与了计算 不会使用索引 比如 left(sname,1)

  当算子两边的操作数类型不一致时，MySQL会发生类型转换以使操作数兼容，这些转换是隐式发生的。下面描述了比较操作的**隐式转换**：

  - 如果一个或两个参数均为NULL，则比较结果为NULL；但是 <=> [相等比较运算符](https://www.zhihu.com/search?q=%E7%9B%B8%E7%AD%89%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)除外，对于ANY <=> NULL，结果为null，无需转换。

  - 如果比较操作中的两个参数都是[字符串](https://www.zhihu.com/search?q=%E5%AD%97%E7%AC%A6%E4%B8%B2&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)，则将它们作为字符串进行比较。

  - 如果两个参数都是整数，则将它们作为整数进行比较。

  - 如果[十六进制](https://www.zhihu.com/search?q=%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)不是和数字作比较，它会被视作是[二进制](https://www.zhihu.com/search?q=%E4%BA%8C%E8%BF%9B%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)字符串。

  - 如果参数之一是TIMESTAMP或DATETIME列，而另一个参数是常量，则在执行比较之前，该常量将转换为[时间戳](https://www.zhihu.com/search?q=%E6%97%B6%E9%97%B4%E6%88%B3&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)，但对于IN() 内的参数不执行此操作。为了安全起见，在进行比较时，请始终使用完整的时间、日期或时间字符串。例如，要在日期和时间参数上使用 BETWEEN 函数时，最好使用 CAST() 函数把参数显示转换成所需的数据类型。

  - 一个或多个表中的[单行子查询](https://www.zhihu.com/search?q=%E5%8D%95%E8%A1%8C%E5%AD%90%E6%9F%A5%E8%AF%A2&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)不视为常量。例如，如果子查询返回的整数要与DATETIME值进行比较，则比较将作为两个整数完成，子查询返回的整数不转换为时间值。参见上一条，这种情况下请使用CAST()将子查询的结果整数值转换为DATETIME。

  - 如果参数之一是十进制值，则比较取决于另一个参数。如果另一个参数是[十进制](https://www.zhihu.com/search?q=%E5%8D%81%E8%BF%9B%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A428772173%7D)或整数值，则将参数作为十进制值进行比较；如果另一个参数是浮点值，则将参数作为浮点值进行比较。

  - **在所有其他情况下，将参数作为浮点数（实数）进行比较**。例如，将字符串和数字操作数进行比较，将其作为浮点数的比较。

    

    所以索引列是字符串时，如果传入的条件参数是整数 

    MySQL在执行我们的查询SQL时，会 **CAST 函数**把每一行主键列的值转换成浮点数，然后再与条件参数做比较。而 InnoDB 存储引擎中，在索引列上使用函数会导致索引失效，所以最后导致了全表扫描。 

* %不会走索引%    %不会走索引    会走索引% 当组合索引时只要所有索引列都参与条件删选 %会走索引%

* 正则表达式也不会使用索引 

* 慢查询

   慢查询能记录下所有执行超过long_query_time时间的SQL语句, 用于找到执行慢的SQL, 方便我们对这些SQL进行优化。 

* 查看开启慢查询状态  show variables like 'slow_query%';

  查看慢查询设置的时间 show variables like "long_query_time"

* 配置 

  set global slow_query_log='ON';

  set session long_query_time=1;

* 全局配置   my.cnf 

  ```
  slow_query_log = ON
  slow_query_log_file = /usr/local/mysql/data/slow.log
  long_query_time = 1
  ```

  

  查看文件路径  mysql --help | grep 'my.cnf' 前面的优先级高

  启动服务器 mysqld --defaults-file=/etc/my.cnf --user=root 

  客户端连接 mysql --defaults-file=/etc/my.cnf -uroot -p123456

  



MySQL是否每次只能使用一个索引？
答案当然不是的，MySQL每次可以使用多个索引，即 index merge（索引合并），但大多数情况下都只会使用一个索引，那这是为什么咧？

1. 为什么会有index merge

MySQL5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。但是从5.1开始，引入了 index merge 优化技术，对同一个表可以使用多个索引分别进行条件扫描
我们的 where 中可能有多个条件(或者join)涉及到多个字段，它们之间进行 AND 或者 OR，那么此时就有可能会使用到 index merge 技术。index merge 技术如果简单的说，其实就是：对多个索引分别进行条件扫描，然后将它们各自的结果进行合并(intersect/union)
索引合并是通过多个range类型的扫描并且合并它们的结果集来检索行的。仅合并来自单个表的索引扫描，而不是跨多个表的索引扫描。合并会产生底层扫描的三种形式：unions（合并）、intersections（交集）、unions-of-intersections（先取交集再合并）
索引合并详细讲解可参考文末推荐阅读
2. 为什么很少见index merge

与其说是“数据库查询只能用到一个索引”，倒不是说是 和全表扫描/只使用一个索引的速度比起来，去分析两个索引二叉树更加耗费时间，所以绝大多数情况下数据库都是是用一个索引。
如这条语句：
select count(1) from table1 where column1 = 1 and column2 = 'foo' and column3 = 'bar'
我们来想象一下当数据库有N个索引并且查询中分别都要用上他们的情况：
查询优化器（用大白话说就是生成执行计划的那个东西）需要进行N次主二叉树查找[这里主二叉树的意思是最外层的索引节点]，此处的查找流程大概如下：
查出第一条column1主二叉树等于1的值，然后去第二条column2主二叉树查出foo的值并且当前行的coumn1必须等于1，最后去column主二叉树查找bar的值并且column1必须等于1和column2必须等于foo。
如果这样的流程被查询优化器执行一遍，就算不死也半条命了，查询优化器可等不及把以上计划都执行一遍，贪婪算法（最近邻居算法）可不允许这种情况的发生，所以当遇到以下语句的时候，数据库只要用到第一个筛选列的索引（column1），就会直接去进行表扫描了。
所以与其说是数据库只支持一条查询语句只使用一个索引，倒不如说N条独立索引同时在一条语句使用的消耗比只使用一个索引还要慢。
所以如上条的情况，最佳推荐是使用index(column1,column2,column3） 这种联合索引，此联合索引可以把b+tree结构的优势发挥得淋漓尽致：
一条主二叉树（column=1），查询到column=1节点后基于当前节点进行二级二叉树column2=foo的查询，在二级二叉树查询到column2=foo后，去三级二叉树column3=bar查找。
当然建了联合索引也需要看数据的分布，索引的可用度高低，尽量把区分度高的字段放前面，或者根据实际的业务场景来做出对字段的先后排序。



可能存在以下情况 索引是(a,b,c)

where b='x' 发现key走了组合索引，再看rows,extra(using where)后，发现原来是走了[覆盖索引](https://so.csdn.net/so/search?q=%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95&spm=1001.2101.3001.7020)，但是查询的时候还是进行了全表扫描，我们可以看到rows=5以及Extra里的Using where，只不过select * 查询的字段恰好能从组合索引（覆盖索引）中取到，优化器会使用该索引，避免去回表查询。





# 缓冲池

![x](.\mysql.assets\x.png)



![2021113115620229](.\mysql.assets\2021113115620229.png)

缓冲池很大程度减少了磁盘 I/O 带来的开销，通过将操作的数据行所在的数据页加载到缓冲池可以提高 SQL 的执行速度。

为了减少磁盘 I/O，Innodb 通过在缓冲池中提前读取多个数据页来进行优化，这种方式叫作预读。

## 数据淘汰

传统LRU淘汰法

Least Recently Used

假设采用数组/链表方式存储数据页,头指针指向最近使用到的页,尾指针则相反

1. 缓存页已经在缓冲池中,将该页放在头部
2. 缓存页不在缓冲池中,将该页放在头部,并淘汰尾部数据页

 存在的问题:

- 预读失效 : 预读的页始终没被mysql读取直到被淘汰

- 缓冲池污染: 一个sql要扫描大量数据时,可能导致缓冲池的所有页都替换初期



解决方法1-预读失效:

将LRU分为两部分 将LRU分为两部分 : 新生代 , 老年代(也可称作冷热区)

新生代 , 老年代首尾相连

新页加入缓冲池前,先加入到老生带头部

- 如果数据真正的被读取,才会加入到老生带中

- 如果数据没有被读取,则会比新生代的"热数据"更早的淘汰出缓冲池

  

![20191111230628282](.\mysql.assets\20191111230628282.png)



解决方法2-缓冲池污染:

![20191111232359139](.\mysql.assets\20191111232359139.png)

参数：innodb_buffer_pool_size  //默认128M
介绍：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。 

参数：innodb_old_blocks_pct
介绍：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。
画外音：如果把这个参数设为100，就退化为普通LRU了。



参数：innodb_old_blocks_time
介绍：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。

# MVCC



全称Multi-Version Concurrency Control，即`多版本并发控制`，主要是为了提高数据库的`并发性能`。以下文章都是围绕InnoDB引擎来讲，因为myIsam不支持事务。

同一行数据平时发生读写请求时，会`上锁阻塞`住。但mvcc用更好的方式去处理读—写请求，做到在发生读—写请求冲突时`不用加锁`。

这个读是指的`快照读`，而不是`当前读`，当前读是一种加锁操作，是`悲观锁`。

### 当前读

它读取的数据库记录，都是`当前最新`的`版本`，会对当前读取的数据进行`加锁`，防止其他事务修改数据。是`悲观锁`的一种操作。

如下操作都是当前读：

- select lock in share mode (共享锁)
- select for update (排他锁)
- update (排他锁)
- insert (排他锁 对新增加的记录添加X锁)
- delete (排他锁)
- 串行化事务隔离级别

### 快照读

快照读的实现是基于`多版本`并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前`历史版本`的数据。

如下操作是快照读：

- 不加锁的select操作（注：事务级别不是串行化）

### 快照读与mvcc的关系

`MVCCC`是“维持一个数据的多个版本，使读写操作没有冲突”的一个`抽象概念`。

这个概念需要具体功能去实现，这个具体实现就是`快照读`。



## 数据库并发场景

- `读-读`：不存在任何问题，也不需要并发控制

- `读-写`：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读

- `写-写`：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

  **第一类丢失更新**(回滚丢失，Lost update) 

  ​    A事务撤销时，把已经提交的B事务的更新数据覆盖了。这种错误可能造成很严重的问题。这是由于**完全没有隔离级别导致的**

  **第二类丢失更新**(覆盖丢失/两次更新问题，Second lost update)  

   A事务（提交）覆盖B事务已经提交的数据，造成B事务所做操作丢失 （必然会发生）

  解决： select  ... for update(悲观锁,~~会直接返回加锁事务修改后的值，与可重复读概念上由冲突~~) 

  ​		原来可重复读的概念是需要先读一次，然后在此之后保证跟第一次读取的数据一致；

  ​		若之前没读，则是读取当前最新的版本（维护select）

  ​		由于 select  ... for update直接加锁，需要cmt/rb解锁 但意味事务的结束 因此没有可重复读的概念

  ​	     版本列(乐观锁)

## MVCC解决并发哪些问题？

mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配`单向增长`的`时间戳`。为每个数据修改保存一个`版本`，版本与事务时间戳`相关联`。

读操作`只读取`该事务`开始前`的`数据库快照`。

**解决问题如下：**

- `并发读-写时`：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。
- 解决`脏读`、`幻读`、`不可重复读`等事务隔离问题，但不能解决上面的`写-写 更新丢失`问题。

**因此有了下面提高并发性能的组合拳：**

- `MVCC + 悲观锁`：MVCC解决读写冲突，悲观锁解决写写冲突
- `MVCC + 乐观锁`：MVCC解决读写冲突，乐观锁解决写写冲突



## MVCC的实现原理

它的实现原理主要是`版本链`，`undo日志` ，`Read View `来实现的

### 版本链

我们数据库中的每行数据，除了我们肉眼看见的数据，还有几个`隐藏字段`，得开`天眼`才能看到。分别是**`db_trx_id`、`db_roll_pointer`、`db_row_id`**。

- db_trx_id

  6byte，最近修改(修改/插入)`事务ID`：记录`创建`这条记录/`最后一次修改`该记录的`事务ID`。

- db_roll_pointer（版本链关键）

  7byte，`回滚指针`，指向`这条记录`的`上一个版本`（存储于rollback segment里）

- db_row_id

  6byte，隐含的`自增ID`（隐藏主键），如果数据表`没有主键`，InnoDB会自动以db_row_id产生一个`聚簇索引`。

- 实际还有一个`删除flag`隐藏字段, 记录被`更新`或`删除`并不代表真的删除，而是`删除flag`变了

![img](https://img.php.cn/upload/article/000/000/052/7d239fc720ed0f548d4d994272398847-2.png)

如上图，`db_row_id`是数据库默认为该行记录生成的`唯一隐式主键`，`db_trx_id`是当前操作该记录的`事务ID`，而`db_roll_pointer`是一个`回滚指针`，用于配合`undo日志`，指向上一个`旧版本`。

每次对数据库记录进行改动，都会记录一条`undo日志`，每条undo日志也都有一个`roll_pointer`属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些`undo日志都连起来`，`串成一个链表`，所以现在的情况就像下图一样：

![img](https://img.php.cn/upload/article/000/000/052/7d239fc720ed0f548d4d994272398847-3.png)

对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被`roll_pointer`属性连接成一个`链表`，我们把这个链表称之为`版本链`，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id，这个信息很重要，在根据ReadView判断版本可见性的时候会用到。

### undo日志

**Undo log 主要用于`记录`数据被`修改之前`的日志，在表信息修改之前先会把数据拷贝到`undo log`里**。

当`事务`进行`回滚时`可以通过undo log 里的日志进行`数据还原`。

**Undo log 的用途**

- 保证`事务`进行`rollback`时的`原子性和一致性`，当事务进行`回滚`的时候可以用undo log的数据进行`恢复`。
- **用于MVCC`快照读`的数据**，在MVCC多版本控制中，通过读取`undo log`的`历史版本数据`可以实现`不同事务版本号`都拥有自己`独立的快照数据版本`。

**undo log主要分为两种：**

- insert undo log

  代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃

- update undo log（主要）

  事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要；

  所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除

### Read View(读视图)

**事务进行`快照读`操作的时候生产的`读视图`(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个`快照`。**

记录并维护系统当前`活跃事务的ID`(没有commit，当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以越新的事务，ID值越大)，是系统中当前不应该被`本事务`看到的`其他事务id列表`。

Read View主要是用来做**可见性**判断的, 即当我们`某个事务`执行`快照读`的时候，对该记录创建一个Read View读视图，把它比作条件**用来判断`当前事务`能够看到`哪个版本`的数据**，既可能是当前`最新`的数据，也有可能是该行记录的undo log里面的`某个版本`的数据。

**Read View几个属性**

- `trx_ids`: 当前系统活跃(`未提交`)事务版本号集合。
- `low_limit_id`: 创建当前read view 时“当前系统`最大事务版本号`+1”。
- `up_limit_id`: 创建当前read view 时“系统正处于活跃事务`最小版本号`”
- `creator_trx_id`: 创建当前read view的事务版本号；

### Read View可见性判断条件

- `db_trx_id` < `up_limit_id` || `db_trx_id` == `creator_trx_id`（显示）

  如果数据事务ID小于read view中的`最小活跃事务ID`，则可以肯定该数据是在`当前事务启之前`就已经`存在`了的,所以可以`显示`。

  或者数据的`事务ID`等于`creator_trx_id` ，那么说明这个数据就是当前事务`自己生成的`，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以`显示`的。

- `db_trx_id` >= `low_limit_id`（不显示）

  如果数据事务ID大于read view 中的当前系统的`最大事务ID`，则说明该数据是在当前read view 创建`之后才产生`的，所以数据`不显示`。如果小于则进入下一个判断

- `db_trx_id`是否在`活跃事务`（trx_ids）中

  - `不存在`：则说明read view产生的时候事务`已经commit`了，这种情况数据则可以`显示`。
  - `已存在`：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的。

![img](https://img.php.cn/upload/article/000/000/052/13716068d9b8460986d4b13c7d992d53-5.png)

## MVCC和事务隔离级别

上面所讲的`Read View`用于支持`RC`（Read Committed，读提交）和`RR`（Repeatable Read，可重复读）`隔离级别`的`实现`。

### RR、RC生成时机

- **`RC`隔离级别**下，是**每个`快照读`都会`生成并获取最新`的`Read View`**；
- 而在**`RR`隔离级别**下，则是`同一个事务中`的**`第一个快照读`才会创建`Read View`**, **`之后的`快照读获取的都是`同一个Read View`**，之后的查询就`不会重复生成`了，所以一个事务的查询结果每次`都是一样的`。

### 解决幻读问题

- `快照读`：通过MVCC来进行控制的，不用加锁。按照MVCC中规定的“语法”进行增删改查等操作，以避免幻读。
- `当前读`：通过next-key锁（行锁+gap锁）来解决问题的。

### RC、RR级别下的InnoDB快照读区别

- 在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；
- 即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见
- 而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因
- **InnoDB** **使用锁和 MVCC 技术来实现并发事务的访问控制技术** 

## 总结

从以上的描述中我们可以看出来，所谓的MVCC指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SEELCT`操作时访问记录的`版本链`的过程，这样子可以使不同事务的`读-写`、`写-读`操作`并发执行`，从而`提升系统性能`。



# 日志



![20200801185443969](.\mysql.assets\20200801185443969.png)

1. redo log本质是保证事务提交之后，修改的数据绝对不会丢失的 

   如果buffer pool的缓存页还没刷到磁盘上去 ,此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍， 恢复出来事务当时更新的缓存页 ，然后再把缓存页刷到磁盘就可以了 



## binlog

`binlog` 用于**记录数据库执行的写入性操作**(不包括查询)信息，**以二进制的形式保存在磁盘中**。`binlog` 是 `mysql`的逻辑日志，并且由 `Server` 层进行记录，使用任何存储引擎的 `mysql` 数据库都会记录 `binlog` 日志。

- **逻辑日志**：可以简单理解为记录的就是sql语句 。
- **物理日志**：`mysql` 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。

`binlog` 是通过追加的方式进行写入的，可以通过`max_binlog_size` 参数设置每个 `binlog`文件的大小(默认1G)，当文件大小达到给定值之后，会生成新的文件来保存日志。

### 使用场景

在实际应用中， `binlog` 的主要使用场景有两个，分别是 **主从复制** 和 **数据恢复** 。

1. **主从复制** ：在 `Master` 端开启 `binlog` ，然后将 `binlog`发送到各个 `Slave` 端， `Slave` 端重放 `binlog` 从而达到主从数据一致。
2. **数据恢复** ：通过使用 `mysqlbinlog` 工具来恢复数据。

### 刷盘时机

对于 `InnoDB` 存储引擎而言，只有在事务提交时才会记录`biglog` ，此时记录还在内存中，那么 `biglog`是什么时候刷到磁盘中的呢？`mysql` 通过 `sync_binlog` 参数控制 `biglog` 的刷盘时机，取值范围是 `0-N`：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次 `commit` 的时候都要将 `binlog` 写入磁盘；
- N：每N个事务，才会将 `binlog` 写入磁盘。

从上面可以看出， `sync_binlog` 最安全的是设置是 `1` ，这也是`MySQL 5.7.7`之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。





### 日志格式

`binlog` 日志有三种格式，分别为 `STATMENT` 、 `ROW` 和 `MIXED`。

> 在 `MySQL 5.7.7` 之前，默认的格式是 `STATEMENT` ， `MySQL 5.7.7` 之后，默认值是 `ROW`。日志格式通过 `binlog_format` 指定。

- `STATMENT`：基于`SQL` 语句的复制( `statement-based replication, SBR` )，每一条会修改数据的sql语句会记录到`binlog` 中 。

- - 优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO , 从而提高了性能；
  - 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate() 、 slepp() 等 。

- `ROW`：基于行的复制(`row-based replication, RBR` )，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。

- - 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；
  - 缺点：会产生大量的日志，尤其是` alter table ` 的时候会让日志暴涨

- `MIXED`：基于`STATMENT` 和 `ROW` 两种模式的混合复制(`mixed-based replication, MBR` )，一般的复制使用`STATEMENT` 模式保存 `binlog` ，对于 `STATEMENT` 模式无法复制的操作使用 `ROW` 模式保存 `binlog`

## redolog

**为什么需要redo log**

我们都知道，事务的四大特性里面有一个是 **持久性** ，具体来说就是**只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态** 。

那么 `mysql`是如何保证持久性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：

1. 因为 `Innodb` 是以 `页` 为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！
2. 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！

因此 `mysql` 设计了 `redo log` ， **具体来说就是只记录事务对数据页做了哪些修改**，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。undolog



### 基本概念

redo log 包括两部分：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件( redo logfile)。mysql 每执行一条 DML 语句，先将记录写入 redo log buffer，后续某个时间点再一次性将多个操作记录写到 redo log file。这种 先写日志，再写磁盘 的技术就是 MySQL里经常说到的 WAL(Write-Ahead Logging) 技术。在计算机操作系统中，用户空间( user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( kernel space )缓冲区( OS Buffer )。因此， **redo log buffer 写入 redo logfile 实际上是先写入 OS Buffer ，然后再通过系统调用 fsync() 将其刷到 redo log file中**

`mysql` 支持三种将 `redo log buffer` 写入 `redo log file` 的时机，可以通过 `innodb_flush_log_at_trx_commit` 参数配置



0 **每隔1 秒钟**会将log buffer中的数据写入到文件 **最极端的情况是丢失1 秒时间的数据变更**

1(默认) **每次事务的结束**log thread将log buffer写入到OS Buffer,**并调用fsync()将其刷新到log file中**  **不会丢失任何已经提交的数据**

2 **每次事务的结束**log thread将log buffer写入到OS Buffer 单并**不调用fsync()将其刷新到log file中**



### redo log记录形式

循环写

redo log的大小是固定的,日志上的记录修改落盘后，日志会被覆盖掉，无法用于数据回滚/数据恢复等操作

### 以上两种区别

由 `binlog` 和 `redo log` 的区别可知：

`binlog` 日志只用于归档，只依靠 `binlog` 是没有 `crash-safe` 能力的。

但只有 `redo log` 也不行，因为 `redo log` 是 `InnoDB`特有的，且日志上的记录落盘后会被覆盖掉。因此需要 `binlog`和 `redo log`二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失

## unlog

数据库事务四大特性中有一个是 **原子性** ，具体来说就是 **原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况**。实际上， **原子性** 底层就是通过 `undo log` 实现的。`undo log`主要记录了数据的逻辑变化，比如一条 `INSERT` 语句，对应一条`DELETE` 的 `undo log` ，对于每个 `UPDATE` 语句，对应一条相反的 `UPDATE` 的 `undo log` ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， `undo log` 也是 `MVCC`(多版本并发控制)实现的关键。























SELECT IFNULL((SELECT  Salary 
FROM Employee2
GROUP BY Salary
ORDER BY Salary DESC
LIMIT 1,1),NULL) AS SecondHighestSalary



5. MOD(A,B)  A%B
6. 建议使用<> 新标准

7.CASE WHEN then不会由具体操作 更多是返回值

8.MySQL 4大排序函数

* row_number在排名时序号 **连续 不重复** 

select row_number() OVER(order by e.salary desc) as row_num , e.salary from employee e 

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190509113254288.png) 

* rank函数会把要求排序的值相同的归为一组且每组序号一样，排序不会连续  **不连续重复**

  select rank() OVER(order by e.salary desc) as row_num , e.salary from employee e 

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190509121220509.png) 

* dense_rank排序是连续的，也会把相同的值分为一组且每组排序号一样  **连续重复**

  select dense_rank() OVER(order by e.salary desc) as row_num , e.salary from employee e 

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190509121514351.png) 

  

* NTILE(group_num)将所有记录分成group_num个组，每组序号一样 执行 select NTILE(2) OVER(order by e.salary desc) as row_num , e.salary from employee e 结果： ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190509123016835.png) 

9. fomat(a,b) 浮点数a固定b位     cast(a as decimal(c,d)) 浮点数a,长度为C(d位的小数)

10. 对个字段 in  相当于元组 得这个元组在表中找到一样的匹配

11. alter table user2 add constraint remark_mul unique(remark)  增加索引 或在建表时 unique(remark)
      alter table user2 drop key remark_mul 删除索引

    alter table user2 add index multiple_remark(remark)  增加重复索引 或在建表时 index(remark)

13. 

